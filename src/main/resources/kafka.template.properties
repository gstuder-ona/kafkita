############################# Server Basics #############################

# The id of the broker. This must be set to a unique integer for each broker.
broker.id=0

# Switch to enable topic deletion or not, default value is false
delete.topic.enable=true

# Keep number of threads low
num.io.threads: 1
num.network.threads: 1
background.threads: 1
num.recovery.threads.per.data.dir: 1

# Default topic log compaction, cleaner running every 30s
log.cleanup.policy=compact
log.cleaner.enable=true
log.cleaner.threads=1
log.cleaner.dedupe.buffer.size=${kafkita.kafka.message.buffer.bytes}
log.cleaner.io.buffer.size=${kafkita.kafka.message.buffer.bytes}
log.retention.check.interval.ms=30000

############################# Socket Server Settings #############################

# The port the socket server listens on1
num.network.threads: 1
background.threads: 1
num.recovery.threads.per.data.dir: 1

# Default topic log compaction, cleaner running every 30s
log.cleanup.policy=compact
log.cleaner.enable=true
log.cleaner.threads=1
port=${kafkita.kafka.port}

# Listen *only* on localhost
host.name=localhost

############################# Log Basics #############################

# A comma separated list of directories under which to store log files
log.dir=${kafkita.kafka.logDir}

# Max bytes in a message
message.max.bytes=${kafkita.kafka.message.max.bytes}
# Log segment files
log.segment.bytes=${kafkita.kafka.log.segment.bytes}
log.index.size.max.bytes=${kafkita.kafka.message.max.bytes}

# Network buffer
socket.request.max.bytes=${kafkita.kafka.message.buffer.bytes}
queued.max.requests=10

# Default single partition per-topic
num.partitions=1

# Store data forever
log.retention.hours=-1
# Don't roll logs (~1000 years)
log.roll.hours=876000

# Store offsets forever (~4000 years)
offsets.retention.minutes=2147483647

# Set replication factors and isr factors to single-node
default.replication.factor=1
offsets.topic.replication.factor=1
offset.storage.replication.factor=1
config.storage.replication.factor=1
status.storage.replication.factor=1
errors.deadletterqueue.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1

############################# Zookeeper #############################

# Zookeeper connection string (see zookeeper docs for details).
# This is a comma separated host:port pairs, each corresponding to a zk
# server. e.g. "127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002".
# You can also append an optional chroot string to the urls to specify the
# root directory for all kafka znodes.
zookeeper.connect=${kafkita.kafka.zookeeper.connect}

############################# Consumers/Producers #############################

# Immediately assign consumers to topics
group.initial.rebalance.delay.ms=0



